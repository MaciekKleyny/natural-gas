{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook I'm going to run a few classification models that will try to predict a direction of a natural gas price change in the next day. The idea is very simple as it's two outputs classification (price going up - 1, price going down - 0). In reality there's a 3rd class as well (no price change), but it was connected with one of the main groups. In practice this task is not trivial as financial time series are changeable over time and hard to predict.\n",
    "\n",
    "# Splitting to train, test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statistics import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle('Data/X.pkl')\n",
    "y = pd.read_pickle('Data/y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.70, shuffle=False)\n",
    "# this order is not a mistake - I want my train set to be located earlier in time than test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing test set to test and validation sets - \n",
    "# each of them contains 15% of all rows (train set - 70%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_daily_change</th>\n",
       "      <th>gas_volatility</th>\n",
       "      <th>gas_daily_gap</th>\n",
       "      <th>rate_2y_daily_change</th>\n",
       "      <th>SP500_daily_change</th>\n",
       "      <th>WTI_daily_change</th>\n",
       "      <th>EurUsd</th>\n",
       "      <th>TTF_daily_change</th>\n",
       "      <th>Storage</th>\n",
       "      <th>GDP_quarterly_change</th>\n",
       "      <th>US_temp</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>filling</th>\n",
       "      <th>gas_daily_change_lag22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-20</th>\n",
       "      <td>-0.030230</td>\n",
       "      <td>0.078554</td>\n",
       "      <td>-0.004232</td>\n",
       "      <td>-0.159091</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.110626</td>\n",
       "      <td>1.0707</td>\n",
       "      <td>-0.029377</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>0.005197</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.017903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-17</th>\n",
       "      <td>0.016986</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.00557</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>1.1671</td>\n",
       "      <td>0.042631</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>-85.799000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.010884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gas_daily_change  gas_volatility  gas_daily_gap  \\\n",
       "Date                                                          \n",
       "2020-03-20         -0.030230        0.078554      -0.004232   \n",
       "2018-09-17          0.016986        0.020611       0.002530   \n",
       "\n",
       "            rate_2y_daily_change  SP500_daily_change  WTI_daily_change  \\\n",
       "Date                                                                     \n",
       "2020-03-20             -0.159091             0.00000         -0.110626   \n",
       "2018-09-17              0.000000            -0.00557         -0.001160   \n",
       "\n",
       "            EurUsd  TTF_daily_change  Storage  GDP_quarterly_change  \\\n",
       "Date                                                                  \n",
       "2020-03-20  1.0707         -0.029377   2043.0              0.005197   \n",
       "2018-09-17  1.1671          0.042631   2636.0              0.005423   \n",
       "\n",
       "              US_temp  Friday  Monday  Thursday  Tuesday  Wednesday  filling  \\\n",
       "Date                                                                           \n",
       "2020-03-20  75.360065       1       0         0        0          0     True   \n",
       "2018-09-17 -85.799000       0       1         0        0          0    False   \n",
       "\n",
       "            gas_daily_change_lag22  \n",
       "Date                                \n",
       "2020-03-20               -0.017903  \n",
       "2018-09-17               -0.010884  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_daily_change</th>\n",
       "      <th>gas_volatility</th>\n",
       "      <th>gas_daily_gap</th>\n",
       "      <th>rate_2y_daily_change</th>\n",
       "      <th>SP500_daily_change</th>\n",
       "      <th>WTI_daily_change</th>\n",
       "      <th>EurUsd</th>\n",
       "      <th>TTF_daily_change</th>\n",
       "      <th>Storage</th>\n",
       "      <th>GDP_quarterly_change</th>\n",
       "      <th>US_temp</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>filling</th>\n",
       "      <th>gas_daily_change_lag22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-14</th>\n",
       "      <td>-0.017749</td>\n",
       "      <td>0.018793</td>\n",
       "      <td>-0.002485</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>1.1689</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>2636.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>-85.799000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.006421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-10</th>\n",
       "      <td>0.011432</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>-0.016031</td>\n",
       "      <td>1.0606</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.001278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gas_daily_change  gas_volatility  gas_daily_gap  \\\n",
       "Date                                                          \n",
       "2018-09-14         -0.017749        0.018793      -0.002485   \n",
       "2017-03-10          0.011432        0.025598       0.004371   \n",
       "\n",
       "            rate_2y_daily_change  SP500_daily_change  WTI_daily_change  \\\n",
       "Date                                                                     \n",
       "2018-09-14              0.007246            0.000275          0.005832   \n",
       "2017-03-10             -0.007299            0.003269         -0.016031   \n",
       "\n",
       "            EurUsd  TTF_daily_change  Storage  GDP_quarterly_change  \\\n",
       "Date                                                                  \n",
       "2018-09-14  1.1689          0.004514   2636.0              0.005423   \n",
       "2017-03-10  1.0606          0.001799   2295.0              0.005423   \n",
       "\n",
       "              US_temp  Friday  Monday  Thursday  Tuesday  Wednesday  filling  \\\n",
       "Date                                                                           \n",
       "2018-09-14 -85.799000       1       0         0        0          0    False   \n",
       "2017-03-10  75.360065       1       0         0        0          0     True   \n",
       "\n",
       "            gas_daily_change_lag22  \n",
       "Date                                \n",
       "2018-09-14               -0.006421  \n",
       "2017-03-10               -0.001278  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_daily_change</th>\n",
       "      <th>gas_volatility</th>\n",
       "      <th>gas_daily_gap</th>\n",
       "      <th>rate_2y_daily_change</th>\n",
       "      <th>SP500_daily_change</th>\n",
       "      <th>WTI_daily_change</th>\n",
       "      <th>EurUsd</th>\n",
       "      <th>TTF_daily_change</th>\n",
       "      <th>Storage</th>\n",
       "      <th>GDP_quarterly_change</th>\n",
       "      <th>US_temp</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>filling</th>\n",
       "      <th>gas_daily_change_lag22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-09</th>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.019889</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>-0.007633</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.026230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-04</th>\n",
       "      <td>-0.000554</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>-0.002399</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>-0.049883</td>\n",
       "      <td>1.3847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>126.992186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.055994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            gas_daily_change  gas_volatility  gas_daily_gap  \\\n",
       "Date                                                          \n",
       "2017-03-09          0.025164        0.033961       0.004137   \n",
       "2010-02-04         -0.000554        0.050406      -0.002399   \n",
       "\n",
       "            rate_2y_daily_change  SP500_daily_change  WTI_daily_change  \\\n",
       "Date                                                                     \n",
       "2017-03-09              0.007353            0.000800         -0.019889   \n",
       "2010-02-04             -0.090909           -0.031141         -0.049883   \n",
       "\n",
       "            EurUsd  TTF_daily_change  Storage  GDP_quarterly_change  \\\n",
       "Date                                                                  \n",
       "2017-03-09  1.0551         -0.007633   2295.0              0.005423   \n",
       "2010-02-04  1.3847          0.000000   2406.0              0.010984   \n",
       "\n",
       "               US_temp  Friday  Monday  Thursday  Tuesday  Wednesday  filling  \\\n",
       "Date                                                                            \n",
       "2017-03-09   75.360065       0       0         1        0          0     True   \n",
       "2010-02-04  126.992186       0       0         1        0          0     True   \n",
       "\n",
       "            gas_daily_change_lag22  \n",
       "Date                                \n",
       "2017-03-09                0.026230  \n",
       "2010-02-04                0.055994  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_val.iloc[[0,-1]]) # just to check datasets' start- and end-dates\n",
    "\n",
    "display(X_test.iloc[[0,-1]])\n",
    "\n",
    "display(X_train.iloc[[0,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gas_daily_change</th>\n",
       "      <th>gas_volatility</th>\n",
       "      <th>gas_daily_gap</th>\n",
       "      <th>rate_2y_daily_change</th>\n",
       "      <th>SP500_daily_change</th>\n",
       "      <th>WTI_daily_change</th>\n",
       "      <th>EurUsd</th>\n",
       "      <th>TTF_daily_change</th>\n",
       "      <th>Storage</th>\n",
       "      <th>GDP_quarterly_change</th>\n",
       "      <th>US_temp</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>filling</th>\n",
       "      <th>gas_daily_change_lag22</th>\n",
       "      <th>gas_target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-03-09</th>\n",
       "      <td>0.025164</td>\n",
       "      <td>0.033961</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.019889</td>\n",
       "      <td>1.0551</td>\n",
       "      <td>-0.007633</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.026230</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-08</th>\n",
       "      <td>0.027266</td>\n",
       "      <td>0.039986</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>-0.002284</td>\n",
       "      <td>-0.053820</td>\n",
       "      <td>1.0556</td>\n",
       "      <td>-0.015634</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.004244</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-07</th>\n",
       "      <td>-0.026543</td>\n",
       "      <td>0.026558</td>\n",
       "      <td>-0.009997</td>\n",
       "      <td>0.007634</td>\n",
       "      <td>-0.002913</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>1.0576</td>\n",
       "      <td>-0.006681</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.038908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-06</th>\n",
       "      <td>0.026176</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>0.029713</td>\n",
       "      <td>-0.007576</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.002438</td>\n",
       "      <td>1.0592</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005997</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-03</th>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.013686</td>\n",
       "      <td>1.0565</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>75.360065</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-10</th>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.026455</td>\n",
       "      <td>0.010964</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.002233</td>\n",
       "      <td>0.010441</td>\n",
       "      <td>1.3740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>126.992186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.051313</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-09</th>\n",
       "      <td>-0.020552</td>\n",
       "      <td>0.038563</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.013040</td>\n",
       "      <td>0.025873</td>\n",
       "      <td>1.3760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>126.992186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-08</th>\n",
       "      <td>-0.020671</td>\n",
       "      <td>0.052583</td>\n",
       "      <td>0.015775</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>-0.008863</td>\n",
       "      <td>0.009833</td>\n",
       "      <td>1.3675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>126.992186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.033783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-05</th>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.038985</td>\n",
       "      <td>0.012740</td>\n",
       "      <td>-0.037500</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>-0.026661</td>\n",
       "      <td>1.3691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>126.992186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.021244</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-02-04</th>\n",
       "      <td>-0.000554</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>-0.002399</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>-0.049883</td>\n",
       "      <td>1.3847</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2406.0</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>126.992186</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.055994</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1781 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gas_daily_change  gas_volatility  gas_daily_gap  \\\n",
       "Date                                                          \n",
       "2017-03-09          0.025164        0.033961       0.004137   \n",
       "2017-03-08          0.027266        0.039986       0.003895   \n",
       "2017-03-07         -0.026543        0.026558      -0.009997   \n",
       "2017-03-06          0.026176        0.032747       0.029713   \n",
       "2017-03-03          0.008203        0.022993       0.004280   \n",
       "...                      ...             ...            ...   \n",
       "2010-02-10          0.000378        0.026455       0.010964   \n",
       "2010-02-09         -0.020552        0.038563       0.003518   \n",
       "2010-02-08         -0.020671        0.052583       0.015775   \n",
       "2010-02-05          0.018279        0.038985       0.012740   \n",
       "2010-02-04         -0.000554        0.050406      -0.002399   \n",
       "\n",
       "            rate_2y_daily_change  SP500_daily_change  WTI_daily_change  \\\n",
       "Date                                                                     \n",
       "2017-03-09              0.007353            0.000800         -0.019889   \n",
       "2017-03-08              0.030303           -0.002284         -0.053820   \n",
       "2017-03-07              0.007634           -0.002913         -0.001128   \n",
       "2017-03-06             -0.007576           -0.003277         -0.002438   \n",
       "2017-03-03              0.000000            0.000504          0.013686   \n",
       "...                          ...                 ...               ...   \n",
       "2010-02-10              0.083333           -0.002233          0.010441   \n",
       "2010-02-09              0.063291            0.013040          0.025873   \n",
       "2010-02-08              0.025974           -0.008863          0.009833   \n",
       "2010-02-05             -0.037500            0.002897         -0.026661   \n",
       "2010-02-04             -0.090909           -0.031141         -0.049883   \n",
       "\n",
       "            EurUsd  TTF_daily_change  Storage  GDP_quarterly_change  \\\n",
       "Date                                                                  \n",
       "2017-03-09  1.0551         -0.007633   2295.0              0.005423   \n",
       "2017-03-08  1.0556         -0.015634   2363.0              0.005423   \n",
       "2017-03-07  1.0576         -0.006681   2363.0              0.005423   \n",
       "2017-03-06  1.0592         -0.009066   2363.0              0.005423   \n",
       "2017-03-03  1.0565          0.000358   2363.0              0.005423   \n",
       "...            ...               ...      ...                   ...   \n",
       "2010-02-10  1.3740          0.000000   2406.0              0.010984   \n",
       "2010-02-09  1.3760          0.000000   2406.0              0.010984   \n",
       "2010-02-08  1.3675          0.000000   2406.0              0.010984   \n",
       "2010-02-05  1.3691          0.000000   2406.0              0.010984   \n",
       "2010-02-04  1.3847          0.000000   2406.0              0.010984   \n",
       "\n",
       "               US_temp  Friday  Monday  Thursday  Tuesday  Wednesday  filling  \\\n",
       "Date                                                                            \n",
       "2017-03-09   75.360065       0       0         1        0          0     True   \n",
       "2017-03-08   75.360065       0       0         0        0          1     True   \n",
       "2017-03-07   75.360065       0       0         0        1          0     True   \n",
       "2017-03-06   75.360065       0       1         0        0          0     True   \n",
       "2017-03-03   75.360065       1       0         0        0          0     True   \n",
       "...                ...     ...     ...       ...      ...        ...      ...   \n",
       "2010-02-10  126.992186       0       0         0        0          1     True   \n",
       "2010-02-09  126.992186       0       0         0        1          0     True   \n",
       "2010-02-08  126.992186       0       1         0        0          0     True   \n",
       "2010-02-05  126.992186       1       0         0        0          0     True   \n",
       "2010-02-04  126.992186       0       0         1        0          0     True   \n",
       "\n",
       "            gas_daily_change_lag22  gas_target  \n",
       "Date                                            \n",
       "2017-03-09                0.026230         1.0  \n",
       "2017-03-08               -0.004244         1.0  \n",
       "2017-03-07               -0.038908         1.0  \n",
       "2017-03-06                0.005997         0.0  \n",
       "2017-03-03                0.016362         1.0  \n",
       "...                            ...         ...  \n",
       "2010-02-10               -0.051313         1.0  \n",
       "2010-02-09               -0.009817         1.0  \n",
       "2010-02-08               -0.033783         0.0  \n",
       "2010-02-05                0.021244         0.0  \n",
       "2010-02-04                0.055994         1.0  \n",
       "\n",
       "[1781 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_train, y_train], axis=1, sort=False) \n",
    "# just to see the whole dataset alongside with the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    901\n",
       "1.0    880\n",
       "Name: gas_target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes are almost equal and there's no need for any modifications of the set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed:   55.4s finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MinMaxScaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0.1, 1.1))),\n",
       "                                       ('Polynomial',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=False,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('Yeo-Johnson',\n",
       "                                        PowerTransformer(copy=True,\n",
       "                                                         method='yeo-johnson',\n",
       "                                                         standard...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               presort=False,\n",
       "                                                               random_state=None,\n",
       "                                                               splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'Decision_Tree__max_depth': [5, 20, 35],\n",
       "                         'PCA__n_components': [10, 50, 100],\n",
       "                         'Polynomial__degree': [1, 2],\n",
       "                         'RFE__n_features_to_select': [150, 100, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('MinMaxScaler', MinMaxScaler(feature_range=(0.1, 1.1))),\n",
    "         ('Polynomial', PolynomialFeatures(include_bias=False)),\n",
    "         ('Yeo-Johnson', PowerTransformer()),\n",
    "         ('RFE', RFE(DecisionTreeClassifier(max_depth=10, min_samples_leaf=25), step=5)),\n",
    "         ('PCA', PCA()),\n",
    "         ('Decision_Tree', DecisionTreeClassifier(min_samples_leaf=25))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {'Polynomial__degree' : [1, 2],\n",
    "          'RFE__n_features_to_select' : [150, 100, 50],\n",
    "          'PCA__n_components' : [10, 50, 100],\n",
    "          'Decision_Tree__max_depth' : [5, 20, 35]}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "CV = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1, error_score=np.nan, cv=tscv)\n",
    "\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Decision_Tree__max_depth': 20,\n",
       " 'PCA__n_components': 50,\n",
       " 'Polynomial__degree': 2,\n",
       " 'RFE__n_features_to_select': 50}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('MinMaxScaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0.1, 1.1))),\n",
       "                ('Polynomial',\n",
       "                 PolynomialFeatures(degree=2, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('Yeo-Johnson',\n",
       "                 PowerTransformer(copy=True, method='yeo-johnson',\n",
       "                                  standardize=True)),\n",
       "                ('RFE',\n",
       "                 RFE(estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                      criterion='gini',...\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('Decision_Tree',\n",
       "                 DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
       "                                        max_depth=20, max_features=None,\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=25,\n",
       "                                        min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        presort=False, random_state=None,\n",
       "                                        splitter='best'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_DecTree_train = CV.best_estimator_.predict(X_train)\n",
    "y_pred_DecTree_test = CV.best_estimator_.predict(X_test)\n",
    "y_pred_DecTree_val = CV.best_estimator_.predict(X_val) # saving it for future validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7288040426726559, 0.5471204188481675)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_DecTree_train, acc_DecTree_test = \\\n",
    "accuracy_score(y_train, y_pred_DecTree_train), accuracy_score(y_test, y_pred_DecTree_test)\n",
    "acc_DecTree_train, acc_DecTree_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  4.2min finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MinMaxScaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0.1, 1.1))),\n",
       "                                       ('Polynomial',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=False,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('Yeo-Johnson',\n",
       "                                        PowerTransformer(copy=True,\n",
       "                                                         method='yeo-johnson',\n",
       "                                                         standard...\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'Log_Regr__C': [0.01, 0.1, 1],\n",
       "                         'Log_Regr__penalty': ['none', 'l1'],\n",
       "                         'PCA__n_components': [10, 50, 100],\n",
       "                         'Polynomial__degree': [1, 2],\n",
       "                         'RFE__n_features_to_select': [150, 100, 50]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('MinMaxScaler', MinMaxScaler(feature_range=(0.1, 1.1))),\n",
    "         ('Polynomial', PolynomialFeatures(include_bias=False)),\n",
    "         ('Yeo-Johnson', PowerTransformer()),\n",
    "         ('RFE', RFE(LogisticRegression(solver='lbfgs', max_iter=300, n_jobs=-1), step=5)),\n",
    "         ('PCA', PCA()),\n",
    "         ('Log_Regr', LogisticRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {'Polynomial__degree' : [1, 2],\n",
    "          'RFE__n_features_to_select' : [150, 100, 50],\n",
    "          'PCA__n_components' : [10, 50, 100],\n",
    "          'Log_Regr__penalty': ['none', 'l1'],\n",
    "          'Log_Regr__C' : [0.01, 0.1, 1]}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "CV = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1, error_score=np.nan, cv=tscv)\n",
    "\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Log_Regr__C': 0.1,\n",
       " 'Log_Regr__penalty': 'l1',\n",
       " 'PCA__n_components': 10,\n",
       " 'Polynomial__degree': 1,\n",
       " 'RFE__n_features_to_select': 150}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('MinMaxScaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0.1, 1.1))),\n",
       "                ('Polynomial',\n",
       "                 PolynomialFeatures(degree=1, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('Yeo-Johnson',\n",
       "                 PowerTransformer(copy=True, method='yeo-johnson',\n",
       "                                  standardize=True)),\n",
       "                ('RFE',\n",
       "                 RFE(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                  dual=False,\n",
       "                                                  fit_...\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=10,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('Log_Regr',\n",
       "                 LogisticRegression(C=0.1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='warn', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_LogReg_train = CV.best_estimator_.predict(X_train)\n",
    "y_pred_LogReg_test = CV.best_estimator_.predict(X_test)\n",
    "y_pred_LogReg_val = CV.best_estimator_.predict(X_val) # saving it for future validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5463222908478383, 0.5261780104712042)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_LogReg_train, acc_LogReg_test = \\\n",
    "accuracy_score(y_train, y_pred_LogReg_train), accuracy_score(y_test, y_pred_LogReg_test)\n",
    "acc_LogReg_train, acc_LogReg_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   18.3s finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MinMaxScaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0.1, 1.1))),\n",
       "                                       ('Polynomial',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=False,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('Yeo-Johnson',\n",
       "                                        PowerTransformer(copy=True,\n",
       "                                                         method='yeo-johnson',\n",
       "                                                         standard...\n",
       "                                        KNeighborsClassifier(algorithm='auto',\n",
       "                                                             leaf_size=30,\n",
       "                                                             metric='minkowski',\n",
       "                                                             metric_params=None,\n",
       "                                                             n_jobs=None,\n",
       "                                                             n_neighbors=5, p=2,\n",
       "                                                             weights='uniform'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'KNN__n_neighbors': [5, 25, 50, 100, 200],\n",
       "                         'PCA__n_components': [10, 50, 100],\n",
       "                         'Polynomial__degree': [1, 2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('MinMaxScaler', MinMaxScaler(feature_range=(0.1, 1.1))),\n",
    "         ('Polynomial', PolynomialFeatures(include_bias=False)),\n",
    "         ('Yeo-Johnson', PowerTransformer()),\n",
    "# KNN algorithm does not have RFE feature selection method as it doesn't provide\n",
    "# coefficients of features\n",
    "         ('PCA', PCA()),\n",
    "         ('KNN', KNeighborsClassifier())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {'Polynomial__degree' : [1, 2],\n",
    "          'PCA__n_components' : [10, 50, 100],\n",
    "          'KNN__n_neighbors' : [5, 25, 50, 100, 200]}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "CV = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1, error_score=np.nan, cv=tscv)\n",
    "\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN__n_neighbors': 100, 'PCA__n_components': 10, 'Polynomial__degree': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('MinMaxScaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0.1, 1.1))),\n",
       "                ('Polynomial',\n",
       "                 PolynomialFeatures(degree=1, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('Yeo-Johnson',\n",
       "                 PowerTransformer(copy=True, method='yeo-johnson',\n",
       "                                  standardize=True)),\n",
       "                ('PCA',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=10,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('KNN',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=100, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_KNN_train = CV.best_estimator_.predict(X_train)\n",
    "y_pred_KNN_test = CV.best_estimator_.predict(X_test)\n",
    "y_pred_KNN_val = CV.best_estimator_.predict(X_val) # saving it for future validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5446378439079169, 0.5026178010471204)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_KNN_train, acc_KNN_test = \\\n",
    "accuracy_score(y_train, y_pred_KNN_train), accuracy_score(y_test, y_pred_KNN_test)\n",
    "acc_KNN_train, acc_KNN_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.4s finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MinMaxScaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0.1, 1.1))),\n",
       "                                       ('Polynomial',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=False,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('Yeo-Johnson',\n",
       "                                        PowerTransformer(copy=True,\n",
       "                                                         method='yeo-johnson',\n",
       "                                                         standard...\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=None,\n",
       "                                            random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('Naive_Bayes',\n",
       "                                        GaussianNB(priors=None,\n",
       "                                                   var_smoothing=1e-09))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'PCA__n_components': [10, 50, 100],\n",
       "                         'Polynomial__degree': [1, 2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('MinMaxScaler', MinMaxScaler(feature_range=(0.1, 1.1))),\n",
    "         ('Polynomial', PolynomialFeatures(include_bias=False)),\n",
    "         ('Yeo-Johnson', PowerTransformer()),\n",
    "         ('PCA', PCA()),\n",
    "         ('Naive_Bayes', GaussianNB())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {'Polynomial__degree' : [1, 2],\n",
    "          'PCA__n_components' : [10, 50, 100]}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "CV = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1, error_score=np.nan, cv=tscv)\n",
    "\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': 10, 'Polynomial__degree': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('MinMaxScaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0.1, 1.1))),\n",
       "                ('Polynomial',\n",
       "                 PolynomialFeatures(degree=1, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('Yeo-Johnson',\n",
       "                 PowerTransformer(copy=True, method='yeo-johnson',\n",
       "                                  standardize=True)),\n",
       "                ('PCA',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=10,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('Naive_Bayes', GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_NaiveBayes_train = CV.best_estimator_.predict(X_train)\n",
    "y_pred_NaiveBayes_test = CV.best_estimator_.predict(X_test)\n",
    "y_pred_NaiveBayes_val = CV.best_estimator_.predict(X_val) # saving it for future validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5306007860752386, 0.518324607329843)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_NaiveBayes_train, acc_NaiveBayes_test = \\\n",
    "accuracy_score(y_train, y_pred_NaiveBayes_train), accuracy_score(y_test, y_pred_NaiveBayes_test)\n",
    "acc_NaiveBayes_train, acc_NaiveBayes_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1620 out of 1620 | elapsed:  6.9min finished\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\PC\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=TimeSeriesSplit(max_train_size=None, n_splits=5),\n",
       "             error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('MinMaxScaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0.1, 1.1))),\n",
       "                                       ('Polynomial',\n",
       "                                        PolynomialFeatures(degree=2,\n",
       "                                                           include_bias=False,\n",
       "                                                           interaction_only=False,\n",
       "                                                           order='C')),\n",
       "                                       ('Yeo-Johnson',\n",
       "                                        PowerTransformer(copy=True,\n",
       "                                                         method='yeo-johnson',\n",
       "                                                         standard...\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'PCA__n_components': [10, 50, 100],\n",
       "                         'Polynomial__degree': [1, 2],\n",
       "                         'RFE__n_features_to_select': [150, 100, 50],\n",
       "                         'Random_Forest__bootstrap': [True, False],\n",
       "                         'Random_Forest__max_depth': [5, 20, 35],\n",
       "                         'Random_Forest__min_samples_leaf': [10, 30, 100]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [('MinMaxScaler', MinMaxScaler(feature_range=(0.1, 1.1))),\n",
    "         ('Polynomial', PolynomialFeatures(include_bias=False)),\n",
    "         ('Yeo-Johnson', PowerTransformer()),\n",
    "         ('RFE', RFE(RandomForestClassifier(max_depth=10, min_samples_leaf=25), step=5)),\n",
    "         ('PCA', PCA()),\n",
    "         ('Random_Forest', RandomForestClassifier(n_jobs=-1))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "params = {'Polynomial__degree' : [1, 2],\n",
    "          'RFE__n_features_to_select' : [150, 100, 50],\n",
    "          'PCA__n_components' : [10, 50, 100],\n",
    "          'Random_Forest__max_depth': [5, 20, 35],\n",
    "          'Random_Forest__min_samples_leaf' : [10, 30, 100],\n",
    "          'Random_Forest__bootstrap' : [True, False]}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "CV = GridSearchCV(pipeline, params, n_jobs=-1, verbose=1, error_score=np.nan, cv=tscv)\n",
    "\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PCA__n_components': 10,\n",
       " 'Polynomial__degree': 1,\n",
       " 'RFE__n_features_to_select': 50,\n",
       " 'Random_Forest__bootstrap': False,\n",
       " 'Random_Forest__max_depth': 35,\n",
       " 'Random_Forest__min_samples_leaf': 30}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('MinMaxScaler',\n",
       "                 MinMaxScaler(copy=True, feature_range=(0.1, 1.1))),\n",
       "                ('Polynomial',\n",
       "                 PolynomialFeatures(degree=1, include_bias=False,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('Yeo-Johnson',\n",
       "                 PowerTransformer(copy=True, method='yeo-johnson',\n",
       "                                  standardize=True)),\n",
       "                ('RFE',\n",
       "                 RFE(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                      class_weight=None,\n",
       "                                                      cr...\n",
       "                 RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "                                        criterion='gini', max_depth=35,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=30,\n",
       "                                        min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=-1,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_RandForest_train = CV.best_estimator_.predict(X_train)\n",
    "y_pred_RandForest_test = CV.best_estimator_.predict(X_test)\n",
    "y_pred_RandForest_val = CV.best_estimator_.predict(X_val) # saving it for future validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7658618753509264, 0.49476439790575916)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_RandForest_train, acc_RandForest_test = \\\n",
    "accuracy_score(y_train, y_pred_RandForest_train), accuracy_score(y_test, y_pred_RandForest_test)\n",
    "acc_RandForest_train, acc_RandForest_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section 5 models have been tested. Soon I'm going to create a prediction that takes all of them into account. I don't want to use those that are worse than a 'dummy' model that always predicts the most common class though, so I'll prepare such model 1st and compare my models to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'Dummy' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the most common class in the train set\n",
    "global mode_classes\n",
    "try:\n",
    "    mode_classes = mode(y_train)\n",
    "except:\n",
    "    mode_classes = 1\n",
    "    \n",
    "mode_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dummy model predictions that can be compared with real labels\n",
    "# using accuracy_score metrics\n",
    "dummy_prediction_train = [mode_classes for el in y_train] \n",
    "dummy_prediction_test = [mode_classes for el in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5058955642897248"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, dummy_prediction_train)\n",
    "# since we have 2 possible labels, it has to be bigger than 50% (50% if classes are equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5157068062827225"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_accuracy = accuracy_score(y_test, dummy_prediction_test)\n",
    "dummy_accuracy\n",
    "# on the other hand this record not necessarily will be greater than 50%\n",
    "# as it compares y_test with the most common class in the y_train set;\n",
    "# in a hard voting predition I'll use just those models who beat this number -\n",
    "# if they don't, they have no predictive power bigger than randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating ensemble prediction\n",
    "\n",
    "I'll pick the models that are better (have higher accuracy on the test set) than 'dummy' model and create an ensemble prediction (hard voting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Logistic Regression\n",
      "Naive Bayes\n",
      "[0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "models_accuracy = [acc_DecTree_test, acc_LogReg_test,\n",
    "          acc_KNN_test, acc_NaiveBayes_test, acc_RandForest_test]\n",
    "\n",
    "models_pred = [y_pred_DecTree_test, y_pred_LogReg_test,\n",
    "              y_pred_KNN_test, y_pred_NaiveBayes_test, y_pred_RandForest_test]\n",
    "\n",
    "models_name = ['Decision Tree', 'Logistic Regression',\n",
    "              'K Nearest Neighbors', 'Naive Bayes', 'Random Forest']\n",
    "\n",
    "n = 0\n",
    "\n",
    "HardVotePrediction_test = [0 for el in y_test]\n",
    "\n",
    "for model_accuracy, model_pred, model_name in zip(models_accuracy, models_pred, models_name):\n",
    "    \n",
    "    if model_accuracy > dummy_accuracy:\n",
    "        HardVotePrediction_test = HardVotePrediction_test+model_pred\n",
    "        n+=1\n",
    "        print(model_name)\n",
    "        \n",
    "if n==0:\n",
    "    print('None of the models can beat random prediction.')\n",
    "    \n",
    "else:\n",
    "    HardVotePrediction_test = (HardVotePrediction_test/n).round()\n",
    "    print(HardVotePrediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5235602094240838"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, HardVotePrediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble prediction using all 5 models\n",
    "\n",
    "Even though some of the models might not have a predictive power themselves, it's possible that they make different types of prediction errors and that they'll actually improve an ensemble prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ...and just to see if using all 5 models for voting would give better results\n",
    "HardVotePredictionAll_test = ((y_pred_DecTree_test+y_pred_LogReg_test+y_pred_KNN_test+\n",
    "                       y_pred_NaiveBayes_test+y_pred_RandForest_test)/5).round()\n",
    "HardVotePredictionAll_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5314136125654451"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, HardVotePredictionAll_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores evaluation and picking the best method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores based on test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5235602094240838"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble model - the best models used\n",
    "accuracy_score(y_test, HardVotePrediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5314136125654451"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble model - all 5 models used\n",
    "accuracy_score(y_test, HardVotePredictionAll_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5471204188481675,\n",
       " 0.5261780104712042,\n",
       " 0.5026178010471204,\n",
       " 0.518324607329843,\n",
       " 0.49476439790575916)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison with 5 single models\n",
    "acc_DecTree_test, acc_LogReg_test, acc_KNN_test, acc_NaiveBayes_test, acc_RandForest_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that prepared models and ensemble model have no or little predictive power.\n",
    "\n",
    "At the time I write this, Random Forest has the best accuracy score, therefore I'll pick it as a recommended choice and check it on the validation set.\n",
    "\n",
    "You might see different scores though as some steps in the process are based on randomness (e.g. train_test_split, building random forest)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5275590551181102"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred_RandForest_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[104,  96],\n",
       "       [ 84,  97]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred_RandForest_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of writing the accuracy score on the validation set is equal to 55,12%.\n",
    "\n",
    "Errors distribution is balanced among classes.\n",
    "\n",
    "When I started the project my goal was to achieve a score as close to 60% as possible, so it's not there yet, but doesn't seem to be hopeless either.\n",
    "\n",
    "My biggest hope lies in different preparation of the features and/or using entirely new features as current temperature or its predictions, more sophisticated models might be worth checking as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
